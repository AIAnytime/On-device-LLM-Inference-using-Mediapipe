# On-device-LLM-Inference-using-Mediapipe
On-device LLM Inference using Mediapipe LLM Inference API.

# LLM Task Sample Setup Guide

This guide provides step-by-step instructions on how to set up and run a sample LLM task on your local machine. Follow these instructions carefully to ensure everything works correctly.

## Prerequisites

Before starting, ensure you have the following installed on your system:
- Python 3.x (or Python 2.x for older versions)
- A modern web browser, preferably Chrome

## Setup Instructions

### 1. Create a Project Folder

First, create a new folder on your device for this task. Name the folder `llm_task`.

```bash
mkdir llm_task

